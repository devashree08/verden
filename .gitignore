"""
Tool: get_all_apps_value_by_user  -> dbo.SPGetAllAppsValueByUser
- Current-month, daily snapshot
- Optional VAST filter (CSV or array)
- Pydantic validation & normalization for inputs
"""

from __future__ import annotations
from typing import Any, Dict, List, Optional, Union

from fastmcp import Context
from pydantic import BaseModel, field_validator
from framework.core.registry import mcp
from framework.core.config import DB_BACKEND
from framework.schemas.outputs import ROWS_OUTPUT


class AllAppsValueParams(BaseModel):
    vast: Optional[Union[str, List[Union[int, str]]]] = None
    limit: int = 1000
    offset: int = 0

    @field_validator("limit")
    @classmethod
    def cap_limit(cls, v: int) -> int:
        return max(1, min(v, 15_000))

    @field_validator("offset")
    @classmethod
    def non_negative_offset(cls, v: int) -> int:
        return max(0, v)

    @field_validator("vast")
    @classmethod
    def normalize_vast(cls, v):
        # Accept CSV or list; normalize to CSV string or None
        if v is None:
            return None
        if isinstance(v, str):
            s = v.strip()
            return s or None
        tokens = []
        for item in v:
            if item is None:
                continue
            s = str(item).strip()
            if s:
                tokens.append(s)
        csv = ",".join(tokens)
        return csv or None


@mcp.tool(
    name="get_all_apps_value_by_user",
    description=(
        "Return current-month application vulnerability counts for the caller's accessible VASTs. "
        "Optionally filter by VAST IDs."
    ),
    output_schema=ROWS_OUTPUT,
)
async def get_all_apps_value_by_user(
    params: AllAppsValueParams,
    ctx: Context = Context.depends(),
) -> Dict[str, List[Dict[str, Any]]]:
    """
    Args (validated by Pydantic):
        vast: VAST IDs as CSV or list (normalized to CSV).
        limit: Max rows (1..15000).
        offset: Row offset (>= 0).
    """
    email = (ctx.get_state("email") or "").lower()

    if DB_BACKEND == "mssql":
        from framework.adapters.mssql import call_sp_allapps_value as run_query
        rows = run_query(email=email, vast=params.vast, limit=params.limit, offset=params.offset)
    else:
        from framework.adapters.bigquery import query_allapps_value as run_query
        rows = run_query(email=email, vast=params.vast, limit=params.limit, offset=params.offset)

    return {"rows": rows}





















"""
Tool: get_all_apps_summary_by_user  -> dbo.SPGetAllAppsSummaryByUser
- Historical monthly snapshots (current month until freeze)
- Optional VAST filter
- Optional report_month ('YYYY-MM' or 'Month YYYY' â†’ 'YYYY-MM-01 00:00:00')
- Pydantic validation & normalization for inputs
"""

from __future__ import annotations
from typing import Any, Dict, List, Optional, Union
from datetime import datetime

from fastmcp import Context
from pydantic import BaseModel, field_validator
from dateutil import parser as dtparse

from framework.core.registry import mcp
from framework.core.config import DB_BACKEND
from framework.schemas.outputs import ROWS_OUTPUT


def _normalize_month_literal(s: Optional[str]) -> Optional[str]:
    if not s:
        return None
    s = s.strip()
    if not s:
        return None
    try:
        if len(s) == 7 and s[4] == "-":  # YYYY-MM
            year = int(s[0:4]); month = int(s[5:7])
            dt = datetime(year, month, 1)
        else:
            dt = dtparse.parse(s).replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return None


class AllAppsSummaryParams(BaseModel):
    vast: Optional[Union[str, List[Union[int, str]]]] = None
    report_month: Optional[str] = None
    limit: int = 1000
    offset: int = 0

    @field_validator("limit")
    @classmethod
    def cap_limit(cls, v: int) -> int:
        return max(1, min(v, 15_000))

    @field_validator("offset")
    @classmethod
    def non_negative_offset(cls, v: int) -> int:
        return max(0, v)

    @field_validator("vast")
    @classmethod
    def normalize_vast(cls, v):
        if v is None:
            return None
        if isinstance(v, str):
            s = v.strip()
            return s or None
        tokens = []
        for item in v:
            if item is None:
                continue
            s = str(item).strip()
            if s:
                tokens.append(s)
        csv = ",".join(tokens)
        return csv or None

    @field_validator("report_month")
    @classmethod
    def normalize_month(cls, v: Optional[str]) -> Optional[str]:
        return _normalize_month_literal(v)


@mcp.tool(
    name="get_all_apps_summary_by_user",
    description=(
        "Return historical monthly summaries for the caller's accessible VASTs. "
        "Supports an optional month filter (e.g., '2024-02' or 'February 2024')."
    ),
    output_schema=ROWS_OUTPUT,
)
async def get_all_apps_summary_by_user(
    params: AllAppsSummaryParams,
    ctx: Context = Context.depends(),
) -> Dict[str, List[Dict[str, Any]]]:
    """
    Args (validated by Pydantic):
        vast: VAST IDs as CSV or list (normalized to CSV).
        report_month: Month (normalized to 'YYYY-MM-01 00:00:00') or None.
        limit: Max rows (1..15000).
        offset: Row offset (>= 0).
    """
    email = (ctx.get_state("email") or "").lower()

    if DB_BACKEND == "mssql":
        from framework.adapters.mssql import call_sp_allapps_summary as run_query
        rows = run_query(
            email=email,
            vast=params.vast,
            report_month=params.report_month,
            limit=params.limit,
            offset=params.offset,
        )
    else:
        from framework.adapters.bigquery import query_allapps_summary as run_query
        rows = run_query(
            email=email,
            vast=params.vast,
            report_month=params.report_month,
            limit=params.limit,
            offset=params.offset,
        )

    return {"rows": rows}














"""
Tool: get_vast_general_by_user  -> dbo.SPGetVastGeneralByUser
- General/compliance data for VASTs (includes decommissioned)
- Pydantic validation & normalization for inputs
"""

from __future__ import annotations
from typing import Any, Dict, List, Optional, Union

from fastmcp import Context
from pydantic import BaseModel, field_validator
from framework.core.registry import mcp
from framework.core.config import DB_BACKEND
from framework.schemas.outputs import ROWS_OUTPUT


class VastGeneralParams(BaseModel):
    vast: Optional[Union[str, List[Union[int, str]]]] = None
    limit: int = 1000
    offset: int = 0

    @field_validator("limit")
    @classmethod
    def cap_limit(cls, v: int) -> int:
        return max(1, min(v, 15_000))

    @field_validator("offset")
    @classmethod
    def non_negative_offset(cls, v: int) -> int:
        return max(0, v)

    @field_validator("vast")
    @classmethod
    def normalize_vast(cls, v):
        if v is None:
            return None
        if isinstance(v, str):
            s = v.strip()
            return s or None
        tokens = []
        for item in v:
            if item is None:
                continue
            s = str(item).strip()
            if s:
                tokens.append(s)
        csv = ",".join(tokens)
        return csv or None


@mcp.tool(
    name="get_vast_general_by_user",
    description=(
        "Return general/compliance attributes (SOX, PCI, rankings, etc.) "
        "for the caller's accessible VASTs. Includes decommissioned."
    ),
    output_schema=ROWS_OUTPUT,
)
async def get_vast_general_by_user(
    params: VastGeneralParams,
    ctx: Context = Context.depends(),
) -> Dict[str, List[Dict[str, Any]]]:
    """
    Args (validated by Pydantic):
        vast: VAST IDs as CSV or list (normalized to CSV).
        limit: Max rows (1..15000).
        offset: Row offset (>= 0).
    """
    email = (ctx.get_state("email") or "").lower()

    if DB_BACKEND == "mssql":
        from framework.adapters.mssql import call_sp_vast_general as run_query
        rows = run_query(email=email, vast=params.vast, limit=params.limit, offset=params.offset)
    else:
        from framework.adapters.bigquery import query_vast_general as run_query
        rows = run_query(email=email, vast=params.vast, limit=params.limit, offset=params.offset)

    return {"rows": rows}






