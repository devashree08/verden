# SQL Server connectivity
SQLSERVER_DRIVER=ODBC Driver 18 for SQL Server
SQLSERVER_SERVER=tcp:myserver.database.windows.net,1433
SQLSERVER_DATABASE=mydb
SQLSERVER_UID=myuser
SQLSERVER_PWD=mypassword
SQLSERVER_ENCRYPT=yes
SQLSERVER_TRUSTCERT=no

# App behavior
POOL_SIZE=8
API_TITLE=ProcBridge API
API_VERSION=1.0.0
API_KEY=changeme-very-secret                # simple header-based auth
# Discovery scope (leave empty to allow all):
PROC_SCHEMA_ALLOWLIST=dbo                  # comma-separated schemas
PROC_NAME_REGEX=^spGet.*|^sp.*             # regex; restricts which procs are registered




 db.py (shared: connection pool, discovery, type mapping, execution)

import os
import queue
import re
import logging
from typing import Any, Dict, List, Optional, Tuple

import pyodbc
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger("db")

# ------------------------------------------------------------------------------
# Build connection string from .env
# ------------------------------------------------------------------------------
def build_conn_str() -> str:
    driver   = os.getenv("SQLSERVER_DRIVER", "ODBC Driver 18 for SQL Server")
    server   = os.getenv("SQLSERVER_SERVER")
    database = os.getenv("SQLSERVER_DATABASE")
    uid      = os.getenv("SQLSERVER_UID")
    pwd      = os.getenv("SQLSERVER_PWD")
    encrypt  = os.getenv("SQLSERVER_ENCRYPT", "yes")
    tsc      = os.getenv("SQLSERVER_TRUSTCERT", "no")
    if not (server and database and uid and pwd):
        raise RuntimeError("Missing SQL Server env vars; check .env")
    # Note: TrustServerCertificate=no with Encrypt=yes is recommended for prod
    return (
        f"Driver={{{driver}}};Server={server};Database={database};"
        f"Encrypt={encrypt};TrustServerCertificate={tsc};"
    ).format(driver=driver)

SQLSERVER_CONN_STR = build_conn_str()
SQLSERVER_UID = os.getenv("SQLSERVER_UID")
SQLSERVER_PWD = os.getenv("SQLSERVER_PWD")

POOL_SIZE = int(os.getenv("POOL_SIZE", "8"))

# ------------------------------------------------------------------------------
# Connection pool
# ------------------------------------------------------------------------------
class ODBCConnectionPool:
    def __init__(self, size: int):
        self._pool: "queue.Queue[pyodbc.Connection]" = queue.Queue(maxsize=size)
        for _ in range(size):
            cnxn = pyodbc.connect(
                SQLSERVER_CONN_STR,
                user=SQLSERVER_UID,
                password=SQLSERVER_PWD,
                autocommit=True,
                timeout=30,
            )
            self._pool.put(cnxn)

    def get(self) -> pyodbc.Connection:
        return self._pool.get()

    def put(self, cnxn: pyodbc.Connection):
        self._pool.put(cnxn)

# ------------------------------------------------------------------------------
# Metadata discovery (procs + parameters)
# ------------------------------------------------------------------------------
# Discovery filters
SCHEMA_ALLOWLIST = {
    s.strip().lower()
    for s in os.getenv("PROC_SCHEMA_ALLOWLIST", "").split(",")
    if s.strip()
}
NAME_REGEX = os.getenv("PROC_NAME_REGEX", "")

def allow_proc(schema: str, name: str) -> bool:
    if SCHEMA_ALLOWLIST and schema.lower() not in SCHEMA_ALLOWLIST:
        return False
    if NAME_REGEX:
        return re.match(NAME_REGEX, name) is not None
    return True

def list_stored_procedures(pool: ODBCConnectionPool) -> List[Tuple[str, str]]:
    """
    Returns list of (schema, proc_name) for procs you can see.
    """
    cnxn = pool.get()
    try:
        cur = cnxn.cursor()
        # sys.procedures excludes system; pair with schema names
        cur.execute("""
            SELECT s.name AS schema_name, p.name AS proc_name
            FROM sys.procedures p
            JOIN sys.schemas s ON s.schema_id = p.schema_id
            WHERE p.is_ms_shipped = 0
            ORDER BY s.name, p.name;
        """)
        procs = [(r[0], r[1]) for r in cur.fetchall()]
        return [(s, p) for (s, p) in procs if allow_proc(s, p)]
    finally:
        pool.put(cnxn)

def get_proc_parameters(pool: ODBCConnectionPool, schema: str, proc: str) -> List[Dict[str, Any]]:
    """
    Returns parameter metadata: name, ordinal, is_output, sql_type, max_length, precision, scale, has_default
    """
    cnxn = pool.get()
    try:
        cur = cnxn.cursor()
        cur.execute("""
            SELECT
                p.parameter_id AS ordinal,
                REPLACE(p.name, '@', '') AS name,
                p.is_output,
                t.name AS sql_type,
                p.max_length,
                p.precision,
                p.scale,
                p.has_default_value
            FROM sys.parameters p
            JOIN sys.types t ON p.user_type_id = t.user_type_id
            WHERE p.object_id = OBJECT_ID(?)
            ORDER BY p.parameter_id;
        """, (f"[{schema}].[{proc}]",))
        rows = cur.fetchall()
        params = []
        for r in rows:
            params.append({
                "ordinal": r[0],
                "name": r[1],
                "is_output": bool(r[2]),
                "sql_type": r[3],
                "max_length": r[4],
                "precision": r[5],
                "scale": r[6],
                "has_default": bool(r[7]),
            })
        return params
    finally:
        pool.put(cnxn)

# ------------------------------------------------------------------------------
# Type mapping and coercion
# ------------------------------------------------------------------------------
def coerce_by_sqltype(sql_type: str, value: Any) -> Any:
    if value is None:
        return None
    t = sql_type.lower()
    try:
        if t in ("int", "smallint", "tinyint"):
            return int(value)
        if t in ("bigint",):
            return int(value)
        if t in ("bit",):
            if isinstance(value, bool):
                return value
            return str(value).strip() in ("1", "true", "True", "yes")
        if t in ("decimal", "numeric", "money", "smallmoney"):
            return float(value)
        if t in ("float", "real"):
            return float(value)
        if t in ("date",):
            return str(value)  # let ODBC parse 'YYYY-MM-DD'
        if t in ("datetime", "datetime2", "smalldatetime", "datetimeoffset", "time"):
            return str(value)  # ISO-8601 best
        # nvarchar/varchar/char/nchar/text/ntext/uniqueidentifier/others → str
        return str(value)  # default to string
    except Exception:
        # Fallback to raw; DB will error if wrong — API layer converts to 400 if we choose
        return value

def make_odbc_call(schema: str, proc: str, params: List[Dict[str, Any]]) -> Tuple[str, Tuple[Any, ...]]:
    """
    Create a {CALL schema.proc (?, ?, ...)} and positional tuple in ordinal order.
    Ignores OUTPUT params on input; returns only SELECT results.
    """
    # Keep only input params in ordinal order
    in_params = [p for p in sorted(params, key=lambda x: x["ordinal"]) if not p["is_output"]]
    placeholders = ", ".join("?" for _ in in_params)
    call = f"{{CALL [{schema}].[{proc}] ({placeholders})}}" if placeholders else f"{{CALL [{schema}].[{proc}]}}"
    values = tuple(p["value"] for p in in_params)
    return call, values

def exec_proc(pool: ODBCConnectionPool, schema: str, proc: str, args: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Execute a proc with named args (dict). Coerces types based on sys.types.
    Returns: list of dict rows (SELECT results).
    """
    cnxn = pool.get()
    try:
        cur = cnxn.cursor()
        # Fetch parameter metadata
        meta = get_proc_parameters(pool, schema, proc)
        # Bind inputs in ordinal order, coercing types
        bound: List[Dict[str, Any]] = []
        for p in meta:
            # OUTPUT params: skip binding as input
            if p["is_output"]:
                continue
            name = p["name"]
            if name not in args and not p["has_default"]:
                raise ValueError(f"Missing required parameter: {name}")
            val = args.get(name, None)
            val = coerce_by_sqltype(p["sql_type"], val)
            bound.append({**p, "value": val})
        call, values = make_odbc_call(schema, proc, bound)
        cur.execute(call, values)
        cols = [c[0] for c in cur.description] if cur.description else []
        rows = [dict(zip(cols, r)) for r in cur.fetchall()] if cur.description else []
        return rows
    finally:
        pool.put(cnxn)




main.py (FastAPI: auto-register endpoints for every stored proc)

import os
import re
import json
import logging
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
from fastapi import FastAPI, APIRouter, Path, Body, Depends, HTTPException, status, Request
from fastapi.responses import JSONResponse
from fastapi.openapi.utils import get_openapi
from pydantic import BaseModel, Field

from db import ODBCConnectionPool, list_stored_procedures, get_proc_parameters, exec_proc

load_dotenv()
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))
logger = logging.getLogger("api")

# ------------------------------------------------------------------------------
# Auth (simple API key header for demo; swap for OAuth/JWT in prod)
# ------------------------------------------------------------------------------
API_KEY = os.getenv("API_KEY", "changeme-very-secret")
def require_api_key(request: Request):
    key = request.headers.get("X-API-Key")
    if key != API_KEY:
        raise HTTPException(status_code=401, detail={"fault": {"faultstring": "Unauthorized", "detail": {"errorcode": "E_UNAUTHORIZED"}}})

# ------------------------------------------------------------------------------
# 42C Error schema models
# ------------------------------------------------------------------------------
class ErrorDetailObject(BaseModel):
    errorcode: str = Field(...)

class ErrorResponse(BaseModel):
    class Fault(BaseModel):
        faultstring: str
        # oneOf enforced at runtime in error_response()
        detail: Any
        class Config:
            extra = "forbid"
    fault: Fault
    class Config:
        extra = "forbid"

def error_response(code: int, fault: str, errors: List[str] | str) -> JSONResponse:
    if isinstance(errors, list):
        detail = [{"errorcode": e} for e in errors[:10]]
    else:
        detail = {"errorcode": errors}
    return JSONResponse(
        status_code=code,
        content={"fault": {"faultstring": fault, "detail": detail}},
    )

# ------------------------------------------------------------------------------
# App + DB pool
# ------------------------------------------------------------------------------
app = FastAPI(
    title=os.getenv("API_TITLE", "ProcBridge API"),
    version=os.getenv("API_VERSION", "1.0.0"),
    description="Expose SQL Server stored procedures as REST endpoints (auto-discovered).",
)
pool: Optional[ODBCConnectionPool] = None

@app.on_event("startup")
def _startup():
    global pool
    pool = ODBCConnectionPool(size=int(os.getenv("POOL_SIZE", "8")))
    # Dynamically add routes for each stored procedure
    register_dynamic_proc_routes()

@app.on_event("shutdown")
def _shutdown():
    # nothing special (pool is closed when process exits)
    pass

# ------------------------------------------------------------------------------
# Dynamic route registration
# ------------------------------------------------------------------------------
router = APIRouter()

class GenericProcParam(BaseModel):
    name: str = Field(..., pattern=r"^[A-Za-z_][A-Za-z0-9_]*$")
    value: Any

class GenericProcCall(BaseModel):
    params: List[GenericProcParam] = Field(default_factory=list, max_items=32)

def build_request_model_for_proc(schema: str, proc: str):
    """
    Return a Pydantic model class with fields for each input param, based on metadata.
    """
    from pydantic import create_model
    meta = get_proc_parameters(pool, schema, proc)
    fields = {}
    for p in meta:
        if p["is_output"]:
            continue
        # For strict docs, try to infer type → keep simple mappings
        t = p["sql_type"].lower()
        py_type = str
        if t in ("int", "smallint", "tinyint", "bigint"):
            py_type = int
        elif t in ("decimal", "numeric", "money", "smallmoney", "float", "real"):
            py_type = float
        elif t in ("bit",):
            py_type = bool
        # Optional if has_default, else required
        default = None if p["has_default"] else ...
        fields[p["name"]] = (py_type, default)
    model = create_model(f"{schema}_{proc}_Request", **fields)  # type: ignore
    return model

def register_proc_route(schema: str, proc: str):
    """
    Adds POST /procs/{schema}.{proc} with request body = parameter object.
    """
    ReqModel = build_request_model_for_proc(schema, proc)
    endpoint_path = f"/procs/{schema}.{proc}"

    @router.post(
        endpoint_path,
        name=f"exec_{schema}_{proc}",
        summary=f"Execute {schema}.{proc}",
        responses={
            400: {"model": ErrorResponse},
            401: {"model": ErrorResponse},
            500: {"model": ErrorResponse},
        },
    )
    def exec_named_proc(
        payload: ReqModel = Body(...),
        _auth: None = Depends(require_api_key),
    ):
        try:
            args = payload.model_dump()
            rows = exec_proc(pool, schema, proc, args)
            return {"rows": rows}
        except ValueError as ve:
            return error_response(400, "Bad Request", "E_BAD_PARAMS")
        except Exception as ex:
            logger.exception("Proc execution failed")
            return error_response(500, "Server error", "E_SERVER")

def register_dynamic_proc_routes():
    procs = list_stored_procedures(pool)
    for schema, proc in procs:
        try:
            register_proc_route(schema, proc)
        except Exception:
            logger.exception("Failed to register route for %s.%s", schema, proc)

app.include_router(router)

# ------------------------------------------------------------------------------
# Generic catch-all executor (if you don’t want per-proc typed routes)
# ------------------------------------------------------------------------------
@app.post(
    "/procs/execute",
    summary="Execute any stored procedure by name (untyped)",
    responses={400: {"model": ErrorResponse}, 401: {"model": ErrorResponse}, 500: {"model": ErrorResponse}},
)
def exec_generic_proc(
    proc: str = Body(..., embed=True, description="Fully-qualified name, e.g., dbo.spGetAppsByUser"),
    body: Dict[str, Any] = Body(default_factory=dict, description="Parameters as {name: value}"),
    _auth: None = Depends(require_api_key),
):
    m = re.match(r"^([A-Za-z_][A-Za-z0-9_]*)\.([A-Za-z_][A-Za-z0-9_]*)$", proc)
    if not m:
        return error_response(400, "Bad Request", "E_BAD_PROC_NAME")
    schema, pname = m.group(1), m.group(2)
    try:
        rows = exec_proc(pool, schema, pname, body or {})
        return {"rows": rows}
    except ValueError:
        return error_response(400, "Bad Request", "E_BAD_PARAMS")
    except Exception:
        logger.exception("Generic proc execution failed")
        return error_response(500, "Server error", "E_SERVER")

# ------------------------------------------------------------------------------
# OpenAPI customizer (register your 42C error schema explicitly)
# ------------------------------------------------------------------------------
def custom_openapi():
    schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )
    schema["openapi"] = "3.1.0"
    comps = schema.setdefault("components", {}).setdefault("schemas", {})
    comps["ErrorResponse"] = {
        "type": "object",
        "additionalProperties": False,
        "properties": {
            "fault": {
                "type": "object",
                "additionalProperties": False,
                "properties": {
                    "faultstring": {"type": "string"},
                    "detail": {
                        "oneOf": [
                            {
                                "type": "object",
                                "properties": {"errorcode": {"type": "string"}},
                                "additionalProperties": False,
                            },
                            {
                                "type": "array",
                                "maxItems": 10,
                                "items": {
                                    "type": "object",
                                    "properties": {"errorcode": {"type": "string"}},
                                    "additionalProperties": False,
                                },
                            },
                        ]
                    },
                },
            }
        },
    }
    # Simple API key security
    schema["components"].setdefault("securitySchemes", {})
    schema["components"]["securitySchemes"]["apiKeyAuth"] = {
        "type": "apiKey",
        "in": "header",
        "name": "X-API-Key",
    }
    schema["security"] = [{"apiKeyAuth": []}]
    return schema

app.openapi = custom_openapi





---
mcp_server.py (FastMCP: dynamically expose each stored proc as an MCP tool)

import os
import logging
from typing import Any, Dict

from dotenv import load_dotenv
from fastmcp import FastMCP, ToolParam, ToolReturn

from db import ODBCConnectionPool, list_stored_procedures, get_proc_parameters, exec_proc

load_dotenv()
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))
logger = logging.getLogger("mcp")

# Start MCP server
mcp = FastMCP("ProcBridge-MCP")   # this is the MCP "service" name
pool = ODBCConnectionPool(size=int(os.getenv("POOL_SIZE", "8")))

def register_mcp_tool(schema: str, proc: str):
    """
    Dynamically creates an MCP tool named "{schema}.{proc}" with params discovered from DB.
    """
    params = get_proc_parameters(pool, schema, proc)
    # FastMCP param declarations for better tool metadata
    tool_params = []
    for p in params:
        if p["is_output"]:
            continue
        # map SQL types to MCP ToolParam type hints (string/number/boolean)
        pt = "string"
        t = p["sql_type"].lower()
        if t in ("int", "smallint", "tinyint", "bigint", "decimal", "numeric", "float", "real"):
            pt = "number"
        elif t == "bit":
            pt = "boolean"
        tool_params.append(ToolParam(name=p["name"], type=pt, required=not p["has_default"]))

    @mcp.tool(name=f"{schema}.{proc}", desc=f"Execute {schema}.{proc}", params=tool_params)
    def _tool(**kwargs) -> ToolReturn:
        """
        Executes the stored procedure and returns rows as JSON.
        """
        try:
            rows = exec_proc(pool, schema, proc, kwargs)
            return ToolReturn.ok({"rows": rows})
        except Exception as e:
            # Return a 42C-like error payload for consistency
            return ToolReturn.error({"fault": {"faultstring": "MCP proc error", "detail": {"errorcode": "E_MCP_PROC"}}})

# Register all tools dynamically
for schema, proc in list_stored_procedures(pool):
    try:
        register_mcp_tool(schema, proc)
    except Exception:
        logger.exception("Failed to register MCP tool for %s.%s", schema, proc)

if __name__ == "__main__":
    # Starts the MCP server (stdio transport by default)
    mcp.run()
